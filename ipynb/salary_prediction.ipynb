{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Job Salary Prediction using Location, Title, and Description of Ad\n",
    "\n",
    "In this notebook, we'll build a network for sentiment classification on Indeed job ads. We'll be using [TFLearn](http://tflearn.org/), a high-level library built on top of TensorFlow. TFLearn makes it simpler to build networks just by defining the layers. \n",
    "We'll start off by importing all the modules we'll need, then load and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import json\n",
    "from tflearn.data_utils import to_categorical\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from lib.indeed_parsing import extract_posts_w_salary_to_df, extract_posts_to_df\n",
    "from lib.preprocess import preprocess_w_salary, preprocess_wo_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping job listings from Indeed.com\n",
    "We will be scraping job listings from Indeed.com using extract_posts_w_salary_to_df query function that I built. As inputs, it takes a list of keywords like 'data scientist' or 'machine learning', a list of cities that you want the job posts to be pulled from and an integer for maximum results per page. This function filters the posts that contain salary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = ['los angeles','chicago','san francisco','seattle','new york','austin',\n",
    "          'philadelphia','atlanta','dallas','portland','phoenix','denver',\n",
    "          'houston','miami','washington']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_posts_w_salary_to_df(keyword=['data scientist'], city_set=cities, max_results_per_city=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleans texts from punctuations and replaces abbreviations to words like: sr to senior, jr to junior and etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_w_salary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting salaries using a Classifier\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. I chose to split the salary range to 3 parts. \n",
    "1. below twentieth 20th\n",
    "2. between 20th and 80th which is within standard deviation\n",
    "3. above 80th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x127c9df98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEFCAYAAAD0cwBnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1248c6518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.distplot(df['salary'], bins=10)\n",
    "ax.axvline(df['salary'].mean(), c='r')\n",
    "ax.axvline(df['salary'].median(), c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentieth = df['salary'].quantile(0.20)\n",
    "eightieth = df['salary'].quantile(0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percent_classifier(col):    \n",
    "    \n",
    "    if col < twentieth:\n",
    "        return 0\n",
    "    elif col >= twentieth and col < eightieth:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary_class'] = df['salary'].apply(percent_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Accuracy Score \n",
    "\n",
    "410 ads out of 664 fall into the largest group of salary ranges which give us approximately 62%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Irrelevant Words \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = stop_words.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(row):\n",
    "    \n",
    "    words = row.split()\n",
    "    clean = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            clean.append(word)\n",
    "            \n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc = df['text'].apply(remove_stop_words).values\n",
    "salary_class = df['salary_class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Dictionary Word to Index \n",
    "\n",
    "To start off, let's count how often each word appears in the data. We'll use this count to encode the text data. This resulting count is known as a [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model). We'll use it to select our vocabulary and build the word vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  1899\n"
     ]
    }
   ],
   "source": [
    "total_counts = Counter()\n",
    "for text in job_desc:\n",
    "    for word in text.split():\n",
    "        total_counts[word] += 1\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'scientist', 'research', 'learning', 'new', 'machine', 'analyst', 'york', 'health', 'senior', 'analytic', 'chicago', 'team', 'python', 'science', 'experience', 'clinical', 'r', 'engineer', 'san', 'francisco', 'analysis', 'looking', 'los', 'angeles', 'public', 'modeling', 'statistical', 'company', 'predictive']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:500]\n",
    "print(vocab[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bay :  4\n"
     ]
    }
   ],
   "source": [
    "print(vocab[-1], ': ', total_counts[vocab[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    word2idx[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/vocab.json', 'w') as outfile:\n",
    "    json.dump(vocab, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/word2idx.json', 'w') as outfile:\n",
    "    json.dump(word2idx, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Text to vector \n",
    "\n",
    "Now we can write a function that converts a some text to a word vector. The function will take a string of words as input and return a vector with the words counted up. Here's the general algorithm to do this:\n",
    "\n",
    "* Initialize the word vector with [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html), it should be the length of the vocabulary.\n",
    "* Split the input string of text into a list of words with `.split(' ')`. Again, if you call `.split()` instead, you'll get slightly different results than what we show here.\n",
    "* For each word in that list, increment the element in the index associated with that word, which you get from `word2idx`.\n",
    "\n",
    "**Note:** Since all words aren't in the `vocab` dictionary, you'll get a key error if you run into one of those words. You can use the `.get` method of the `word2idx` dictionary to specify a default returned value when you make a key error. For example, `word2idx.get(word, None)` returns `None` if `word` doesn't exist in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    word_vec = np.zeros((1, len(vocab)))\n",
    "    for word in text.split():\n",
    "        if word in word2idx.keys():\n",
    "            word_vec[0][word2idx[word]] += 1\n",
    "            \n",
    "    return np.array(word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(job_desc), len(vocab)), dtype=np.int_)\n",
    "for ii, text in enumerate(job_desc):\n",
    "    word_vectors[ii] = text_to_vector(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the first 5 word vectors\n",
    "word_vectors[:5, :23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test sets\n",
    "\n",
    "Now that we have the word_vectors, we're ready to split our data into train, validation, and test sets. Remember that we train on the train data, use the validation data to set the hyperparameters, and at the very end measure the network performance on the test data. Here we're using the function `to_categorical` from TFLearn to reshape the target data so that we'll have two output units and can classify with a softmax activation function. We actually won't be creating the validation set here, TFLearn will do that for us later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = salary_class\n",
    "records = len(salary_class)\n",
    "\n",
    "shuffle = np.arange(records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.8\n",
    "\n",
    "train_split, test_split = shuffle[:int(records*test_fraction)], shuffle[int(records*test_fraction):]\n",
    "trainX, trainY = word_vectors[train_split,:], to_categorical(y[train_split], 3)\n",
    "testX, testY = word_vectors[test_split,:], to_categorical(y[test_split], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "[TFLearn](http://tflearn.org/) lets you build the network by [defining the layers](http://tflearn.org/layers/core/). \n",
    "\n",
    "### Input layer\n",
    "\n",
    "For the input layer, you just need to tell it how many units you have. For example, \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 100])\n",
    "```\n",
    "\n",
    "would create a network with 100 input units. The first element in the list, `None` in this case, sets the batch size. Setting it to `None` here leaves it at the default batch size.\n",
    "\n",
    "The number of inputs to your network needs to match the size of your data. For this example, we're using 500 element long vectors to encode our input data, so we need 500 input units.\n",
    "\n",
    "\n",
    "### Adding layers\n",
    "\n",
    "To add new hidden layers, you use \n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, n_units, activation='ReLU')\n",
    "```\n",
    "\n",
    "This adds a fully connected layer where every unit in the previous layer is connected to every unit in this layer. The first argument `net` is the network you created in the `tflearn.input_data` call. It's telling the network to use the output of the previous layer as the input to this layer. You can set the number of units in the layer with `n_units`, and set the activation function with the `activation` keyword. You can keep adding layers to your network by repeated calling `net = tflearn.fully_connected(net, n_units)`.\n",
    "\n",
    "### Output layer\n",
    "\n",
    "The last layer you add is used as the output layer. Therefore, you need to set the number of units to match the target data. In this case we are predicting two classes, positive or negative sentiment. You also need to set the activation function so it's appropriate for your model. Again, we're trying to predict if some input data belongs to one of two classes, so we should use softmax.\n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "```\n",
    "\n",
    "### Training\n",
    "To set how you train the network, use \n",
    "\n",
    "```\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "Again, this is passing in the network you've been building. The keywords: \n",
    "\n",
    "* `optimizer` sets the training method, here stochastic gradient descent\n",
    "* `learning_rate` is the learning rate\n",
    "* `loss` determines how the network error is calculated. In this example, with the categorical cross-entropy.\n",
    "\n",
    "Finally you put all this together to create the model with `tflearn.DNN(net)`. So it ends up looking something like \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 10])                          # Input\n",
    "net = tflearn.fully_connected(net, 5, activation='ReLU')      # Hidden\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(net)\n",
    "```\n",
    "\n",
    "> **Exercise:** Below in the `build_model()` function, you'll put together the network using TFLearn. You get to choose how many layers to use, how many hidden units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Inputs\n",
    "    inputs = tflearn.input_data([None, 500])\n",
    "    \n",
    "    # Hidden layer(s)\n",
    "    full_layer = tflearn.fully_connected(inputs, 500, activation='ReLU')\n",
    "    drop = tflearn.dropout(full_layer, keep_prob=0.3)\n",
    "    \n",
    "    # Output layer(s)\n",
    "    net = tflearn.fully_connected(drop, 3, activation='softmax')\n",
    "    sgd = tflearn.optimizers.SGD(learning_rate=0.01, lr_decay=0.90, decay_step=1000)\n",
    "    net = tflearn.regression(net, optimizer=sgd, loss='categorical_crossentropy')\n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intializing the model\n",
    "\n",
    "Next we need to call the `build_model()` function to actually build the model. In my solution I haven't included any arguments to the function, but you can add arguments so you can change parameters in the model if you want.\n",
    "\n",
    "> **Note:** You might get a bunch of warnings here. TFLearn uses a lot of deprecated code in TensorFlow. Hopefully it gets updated to the new TensorFlow version soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Now that we've constructed the network, saved as the variable `model`, we can fit it to the data. Here we use the `model.fit` method. You pass in the training features `trainX` and the training targets `trainY`. Below I set `validation_set=0.3` which reserves 30% of the data set as the validation set. You can also set the batch size and number of epochs with the `batch_size` and `n_epoch` keywords, respectively. Below is the code to fit our the network to our word vectors.\n",
    "\n",
    "You can rerun `model.fit` to train the network further if you think you can increase the validation accuracy. Remember, all hyperparameter adjustments must be done using the validation set. **Only use the test set after you're completely done training the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.83877\u001b[0m\u001b[0m | time: 0.057s\n",
      "| SGD | epoch: 100 | loss: 0.83877 - acc: 0.5757 -- iter: 320/371\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.83650\u001b[0m\u001b[0m | time: 1.072s\n",
      "| SGD | epoch: 100 | loss: 0.83650 - acc: 0.5759 | val_loss: 0.90355 - val_acc: 0.5375 -- iter: 371/371\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.3, show_metric=True, batch_size=64, n_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3599  | total loss: \u001b[1m\u001b[32m0.43287\u001b[0m\u001b[0m | time: 0.044s\n",
      "| SGD | epoch: 600 | loss: 0.43287 - acc: 0.8878 -- iter: 320/371\n",
      "Training Step: 3600  | total loss: \u001b[1m\u001b[32m0.41484\u001b[0m\u001b[0m | time: 1.059s\n",
      "| SGD | epoch: 600 | loss: 0.41484 - acc: 0.8990 | val_loss: 0.53872 - val_acc: 0.7750 -- iter: 371/371\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_set=0.3, show_metric=True, batch_size=64, n_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9599  | total loss: \u001b[1m\u001b[32m0.12498\u001b[0m\u001b[0m | time: 0.041s\n",
      "| SGD | epoch: 1600 | loss: 0.12498 - acc: 0.9875 -- iter: 320/371\n",
      "Training Step: 9600  | total loss: \u001b[1m\u001b[32m0.12184\u001b[0m\u001b[0m | time: 1.052s\n",
      "| SGD | epoch: 1600 | loss: 0.12184 - acc: 0.9888 | val_loss: 0.33131 - val_acc: 0.8625 -- iter: 371/371\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_set=0.3, show_metric=True, batch_size=64, n_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 21599  | total loss: \u001b[1m\u001b[32m0.06418\u001b[0m\u001b[0m | time: 0.067s\n",
      "| SGD | epoch: 3600 | loss: 0.06418 - acc: 0.9974 -- iter: 320/371\n",
      "Training Step: 21600  | total loss: \u001b[1m\u001b[32m0.06445\u001b[0m\u001b[0m | time: 1.083s\n",
      "| SGD | epoch: 3600 | loss: 0.06445 - acc: 0.9977 | val_loss: 0.24793 - val_acc: 0.9375 -- iter: 371/371\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_set=0.3, show_metric=True, batch_size=64, n_epoch=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 51599  | total loss: \u001b[1m\u001b[32m0.07704\u001b[0m\u001b[0m | time: 0.043s\n",
      "| SGD | epoch: 8600 | loss: 0.07704 - acc: 0.9960 -- iter: 320/371\n",
      "Training Step: 51600  | total loss: \u001b[1m\u001b[32m0.07705\u001b[0m\u001b[0m | time: 1.060s\n",
      "| SGD | epoch: 8600 | loss: 0.07705 - acc: 0.9949 | val_loss: 0.08964 - val_acc: 0.9812 -- iter: 371/371\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_set=0.3, show_metric=True, batch_size=64, n_epoch=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 93599  | total loss: \u001b[1m\u001b[32m0.09166\u001b[0m\u001b[0m | time: 0.044s\n",
      "| SGD | epoch: 15600 | loss: 0.09166 - acc: 0.9880 -- iter: 320/371\n",
      "Training Step: 93600  | total loss: \u001b[1m\u001b[32m0.08922\u001b[0m\u001b[0m | time: 1.059s\n",
      "| SGD | epoch: 15600 | loss: 0.08922 - acc: 0.9892 | val_loss: 0.06805 - val_acc: 0.9938 -- iter: 371/371\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_set=0.3, show_metric=True, batch_size=64, n_epoch=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/leylamovahedi/dsi/dsi-sm/indeed-salary-prediction/model/model.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# Save a model\n",
    "model.save('model/model.tfl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/leylamovahedi/dsi/dsi-sm/indeed-salary-prediction/model/model.tfl\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model.load('model/model.tfl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "After you're satisified with your hyperparameters, you can run the network on the test set to measure its performance. Remember, *only do this after finalizing the hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.857142857143\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(np.array(model.predict(testX)), axis=1)\n",
    "actual = np.argmax(testY, axis=1)\n",
    "test_accuracy = np.mean(predictions == actual)\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = extract_posts_to_df(keyword=['data scientist'], city_set=cities, max_results_per_city=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocess_wo_salary(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_salary(df):\n",
    "    \n",
    "    salary = {'0':'below $66000', '1':'$66000 to $150000', '2':'above $150000'}\n",
    "    \n",
    "    texts = df['text'].apply(remove_stop_words).values\n",
    "    test_vectors = np.zeros((len(texts), len(vocab)), dtype=np.int_)\n",
    "    for ii, text in enumerate(texts):\n",
    "        test_vectors[ii] = text_to_vector(text)\n",
    "        \n",
    "    predicted_salary_class = np.argmax(np.array(model.predict(test_vectors)), axis=1)\n",
    "    df['predicted_salary_range'] = [salary[str(elm)] if str(elm) in salary.keys() else None for elm in predicted_salary_class]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_salary_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>amazon corporate llc</td>\n",
       "      <td>Manhattan Beach, CA</td>\n",
       "      <td>our natural language processing and machine le...</td>\n",
       "      <td>applied scientist</td>\n",
       "      <td>los angeles our natural language processing an...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>goleta star</td>\n",
       "      <td>Torrance, CA</td>\n",
       "      <td>experience with the hough transform support ve...</td>\n",
       "      <td>image analysis scientist</td>\n",
       "      <td>los angeles experience with the hough transfor...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>anthem inc</td>\n",
       "      <td>Downey, CA</td>\n",
       "      <td>model document and present strategic solution ...</td>\n",
       "      <td>healthcare data scientist 127549</td>\n",
       "      <td>los angeles model document and present strateg...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>jet propulsion laboratory</td>\n",
       "      <td>Pasadena, CA</td>\n",
       "      <td>this individual will be responsible for applyi...</td>\n",
       "      <td>data scientist i</td>\n",
       "      <td>los angeles this individual will be responsibl...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>neohire south</td>\n",
       "      <td>Century City, CA</td>\n",
       "      <td>proven ability to do analytic or modeling work...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>los angeles proven ability to do analytic or m...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>sony pictures entertainment inc</td>\n",
       "      <td>Culver City, CA 90232</td>\n",
       "      <td>reporting to senior vp analytic business insig...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>los angeles reporting to senior vp analytic bu...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>spacex</td>\n",
       "      <td>Hawthorne, CA</td>\n",
       "      <td>as a data scientist in this team you would ide...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>los angeles as a data scientist in this team y...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>hulu</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>we are looking for data scientist who are pass...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>los angeles we are looking for data scientist ...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>air liquide</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>cr er des relations solides avec les quipes re...</td>\n",
       "      <td>digital data scientist h f</td>\n",
       "      <td>los angeles cr er des relations solides avec l...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>grindr</td>\n",
       "      <td>Los Angeles, CA 90046</td>\n",
       "      <td>the data scientist will work cross functionall...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>los angeles the data scientist will work cross...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>loot crate</td>\n",
       "      <td>Los Angeles, CA 90031</td>\n",
       "      <td>lead predictive analytic and machine learning ...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>los angeles lead predictive analytic and machi...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>bcg digital ventures</td>\n",
       "      <td>Manhattan Beach, CA</td>\n",
       "      <td>e g real time data reporting and visualization...</td>\n",
       "      <td>data scientist b2b ecommerce startup portfolio...</td>\n",
       "      <td>los angeles e g real time data reporting and v...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>goat</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>proficiency in statistical analytic and machin...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>los angeles proficiency in statistical analyti...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>yomdle inc</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>co founded by accomplished scientist with deep...</td>\n",
       "      <td>machine learning research engineer</td>\n",
       "      <td>los angeles co founded by accomplished scienti...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chicago</td>\n",
       "      <td>invesco</td>\n",
       "      <td>Downers Grove, IL 60515</td>\n",
       "      <td>proficiency in statistical data analysis and d...</td>\n",
       "      <td>data scientist sales analytic</td>\n",
       "      <td>chicago proficiency in statistical data analys...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chicago</td>\n",
       "      <td>vizient inc</td>\n",
       "      <td>Chicago, IL 60606</td>\n",
       "      <td>serves as the resident data expert and share b...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago serves as the resident data expert and...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chicago</td>\n",
       "      <td>predictive science</td>\n",
       "      <td>United States</td>\n",
       "      <td>this is a freelance data scientist position wh...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago this is a freelance data scientist pos...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chicago</td>\n",
       "      <td>xaqt</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>your primary focus will be in applying data mi...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago your primary focus will be in applying...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chicago</td>\n",
       "      <td>amtrust financial services</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>demonstrated skills in data mining machine lea...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago demonstrated skills in data mining mac...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chicago</td>\n",
       "      <td>cars com</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>deep understanding of machine learning and dat...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago deep understanding of machine learning...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chicago</td>\n",
       "      <td>northwestern university</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>individual will be mentored by a faculty membe...</td>\n",
       "      <td>statistical analyst</td>\n",
       "      <td>chicago individual will be mentored by a facul...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chicago</td>\n",
       "      <td>kar auction services inc</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>interpret problems and develop solutions to bu...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago interpret problems and develop solutio...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chicago</td>\n",
       "      <td>bp</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>this may include the creation of specialist in...</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>chicago this may include the creation of speci...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chicago</td>\n",
       "      <td>bmo financial group</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>analyze financial data to extract relevant inf...</td>\n",
       "      <td>quantitative analyst</td>\n",
       "      <td>chicago analyze financial data to extract rele...</td>\n",
       "      <td>below $66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chicago</td>\n",
       "      <td>pathfinder</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>to apply please send your resume to careers pa...</td>\n",
       "      <td>data scientist chicago</td>\n",
       "      <td>chicago to apply please send your resume to ca...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chicago</td>\n",
       "      <td>ann robert h lurie children s hospital of chica</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>the data scientist will work within the data a...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago the data scientist will work within th...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chicago</td>\n",
       "      <td>brady corporation</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>data scientist americas you will be ultimately...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>chicago data scientist americas you will be ul...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chicago</td>\n",
       "      <td>lucas group</td>\n",
       "      <td>Chicago, IL 60606</td>\n",
       "      <td>analytic services where the data scientist wor...</td>\n",
       "      <td>data scientist consultant</td>\n",
       "      <td>chicago analytic services where the data scien...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chicago</td>\n",
       "      <td>abbott laboratories</td>\n",
       "      <td>Lake Forest, IL</td>\n",
       "      <td>the candidate will be responsible for working ...</td>\n",
       "      <td>informatics data scientist</td>\n",
       "      <td>chicago the candidate will be responsible for ...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>san francisco</td>\n",
       "      <td>komodo health</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>komodo health is transforming predictive analy...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>san francisco komodo health is transforming pr...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>houston</td>\n",
       "      <td>predictive science</td>\n",
       "      <td>United States</td>\n",
       "      <td>this is a freelance data scientist position wh...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>houston this is a freelance data scientist pos...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>miami</td>\n",
       "      <td>waltham technologies</td>\n",
       "      <td>Miami, FL 33176</td>\n",
       "      <td>the data scientist will create meaningful data...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>miami the data scientist will create meaningfu...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>miami</td>\n",
       "      <td>amazon corporate llc</td>\n",
       "      <td>United States</td>\n",
       "      <td>advanced working knowledge of data mining usin...</td>\n",
       "      <td>data analyst devices customer engagement reloc...</td>\n",
       "      <td>miami advanced working knowledge of data minin...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>miami</td>\n",
       "      <td>amazon web services inc</td>\n",
       "      <td>United States</td>\n",
       "      <td>as a machine learning software dev engineer on...</td>\n",
       "      <td>machine learning software development engineer...</td>\n",
       "      <td>miami as a machine learning software dev engin...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>miami</td>\n",
       "      <td>ecs</td>\n",
       "      <td>Miami, FL 33133 (North Coconut Grove area)</td>\n",
       "      <td>hands on with a high degree of expertise in da...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>miami hands on with a high degree of expertise...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>miami</td>\n",
       "      <td>ace talent curators</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>python or r for data science turn data into va...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>miami python or r for data science turn data i...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>miami</td>\n",
       "      <td>1st merchant funding</td>\n",
       "      <td>Miami, FL 33181</td>\n",
       "      <td>we are looking for top data scientist experien...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>miami we are looking for top data scientist ex...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>miami</td>\n",
       "      <td>miami dade college</td>\n",
       "      <td>Miami, FL 33132 (Downtown area)</td>\n",
       "      <td>researches and circulates grant program priori...</td>\n",
       "      <td>part time grant research analyst</td>\n",
       "      <td>miami researches and circulates grant program ...</td>\n",
       "      <td>below $66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>miami</td>\n",
       "      <td>lennar</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>applied analytic team and inspire the adoption...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>miami applied analytic team and inspire the ad...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>miami</td>\n",
       "      <td>dynamix int</td>\n",
       "      <td>Fort Lauderdale, FL 33312</td>\n",
       "      <td>the candidate must have an extreme attention t...</td>\n",
       "      <td>market research and data analyst</td>\n",
       "      <td>miami the candidate must have an extreme atten...</td>\n",
       "      <td>below $66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>miami</td>\n",
       "      <td>university of miami</td>\n",
       "      <td>Coral Gables, FL</td>\n",
       "      <td>uhealth university of miami health system sout...</td>\n",
       "      <td>assistant scientist</td>\n",
       "      <td>miami uhealth university of miami health syste...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>miami</td>\n",
       "      <td>adp</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>at adp the worlds largest b2b cloud company ou...</td>\n",
       "      <td>principal product manager business intelligenc...</td>\n",
       "      <td>miami at adp the worlds largest b2b cloud comp...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>miami</td>\n",
       "      <td>university of miami</td>\n",
       "      <td>Coral Gables, FL</td>\n",
       "      <td>experience with data warehousing and reporting...</td>\n",
       "      <td>research analyst</td>\n",
       "      <td>miami experience with data warehousing and rep...</td>\n",
       "      <td>below $66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>miami</td>\n",
       "      <td>amazon corporate llc</td>\n",
       "      <td>United States</td>\n",
       "      <td>working with scientist and other engineers to ...</td>\n",
       "      <td>artificial intelligence research software deve...</td>\n",
       "      <td>miami working with scientist and other enginee...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>miami</td>\n",
       "      <td>predictive science</td>\n",
       "      <td>United States</td>\n",
       "      <td>this is a freelance data scientist position wh...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>miami this is a freelance data scientist posit...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>washington</td>\n",
       "      <td>kpmg</td>\n",
       "      <td>Seattle, WA 98104</td>\n",
       "      <td>machine learning data visualization statistica...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington machine learning data visualization...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>washington</td>\n",
       "      <td>amazon corporate llc</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>4 years of relevant work experience in data sc...</td>\n",
       "      <td>data scientist private label apparel</td>\n",
       "      <td>washington 4 years of relevant work experience...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>washington</td>\n",
       "      <td>zillow</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>experience mentoring leading other data scient...</td>\n",
       "      <td>principal data scientist</td>\n",
       "      <td>washington experience mentoring leading other ...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>washington</td>\n",
       "      <td>amazon corporate llc</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2 years of industrial or research experience i...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington 2 years of industrial or research e...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>washington</td>\n",
       "      <td>thirdeye data inc</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>build solutions that will be applied in real t...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington build solutions that will be applie...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>washington</td>\n",
       "      <td>boeing</td>\n",
       "      <td>Tukwila, WA</td>\n",
       "      <td>as a member of the boeing commercial artificia...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington as a member of the boeing commercia...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>washington</td>\n",
       "      <td>t mobile</td>\n",
       "      <td>Bellevue, WA 98006 (Somerset area)</td>\n",
       "      <td>conduct regular and ad hoc analyses data minin...</td>\n",
       "      <td>marketing data scientist</td>\n",
       "      <td>washington conduct regular and ad hoc analyses...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>washington</td>\n",
       "      <td>winigent</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>we are looking for people who see challenges a...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington we are looking for people who see c...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>washington</td>\n",
       "      <td>idealseat</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>idealseat data scientist are focused on collec...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington idealseat data scientist are focuse...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>washington</td>\n",
       "      <td>google</td>\n",
       "      <td>Kirkland, WA</td>\n",
       "      <td>deep interest and aptitude in data metrics ana...</td>\n",
       "      <td>product analyst data science</td>\n",
       "      <td>washington deep interest and aptitude in data ...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>washington</td>\n",
       "      <td>lyft corporate</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>data scientist also build evaluation methodolo...</td>\n",
       "      <td>data scientist all levels seattle</td>\n",
       "      <td>washington data scientist also build evaluatio...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>washington</td>\n",
       "      <td>textio</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>our augmented writing platform is delighting c...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington our augmented writing platform is d...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>washington</td>\n",
       "      <td>general electric</td>\n",
       "      <td>Washington State</td>\n",
       "      <td>work in technical teams in development deploym...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>washington work in technical teams in developm...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>washington</td>\n",
       "      <td>thrift books</td>\n",
       "      <td>Tukwila, WA</td>\n",
       "      <td>experience with pandas scikit learn and other ...</td>\n",
       "      <td>data scientist and predictive analytic manager</td>\n",
       "      <td>washington experience with pandas scikit learn...</td>\n",
       "      <td>above $150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>washington</td>\n",
       "      <td>meter group</td>\n",
       "      <td>Pullman, WA</td>\n",
       "      <td>data engineering data mining data visualizatio...</td>\n",
       "      <td>applied data scientist</td>\n",
       "      <td>washington data engineering data mining data v...</td>\n",
       "      <td>$66000 to $150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              city                                          company  \\\n",
       "0      los angeles                             amazon corporate llc   \n",
       "1      los angeles                                      goleta star   \n",
       "2      los angeles                                       anthem inc   \n",
       "3      los angeles                        jet propulsion laboratory   \n",
       "4      los angeles                                    neohire south   \n",
       "5      los angeles                  sony pictures entertainment inc   \n",
       "6      los angeles                                           spacex   \n",
       "7      los angeles                                             hulu   \n",
       "8      los angeles                                      air liquide   \n",
       "9      los angeles                                           grindr   \n",
       "10     los angeles                                       loot crate   \n",
       "11     los angeles                             bcg digital ventures   \n",
       "12     los angeles                                             goat   \n",
       "13     los angeles                                       yomdle inc   \n",
       "14         chicago                                          invesco   \n",
       "15         chicago                                      vizient inc   \n",
       "16         chicago                               predictive science   \n",
       "17         chicago                                             xaqt   \n",
       "18         chicago                       amtrust financial services   \n",
       "19         chicago                                         cars com   \n",
       "20         chicago                          northwestern university   \n",
       "21         chicago                         kar auction services inc   \n",
       "22         chicago                                               bp   \n",
       "23         chicago                              bmo financial group   \n",
       "24         chicago                                       pathfinder   \n",
       "25         chicago  ann robert h lurie children s hospital of chica   \n",
       "26         chicago                                brady corporation   \n",
       "27         chicago                                      lucas group   \n",
       "28         chicago                              abbott laboratories   \n",
       "29   san francisco                                    komodo health   \n",
       "..             ...                                              ...   \n",
       "193        houston                               predictive science   \n",
       "194          miami                             waltham technologies   \n",
       "195          miami                             amazon corporate llc   \n",
       "196          miami                          amazon web services inc   \n",
       "197          miami                                              ecs   \n",
       "198          miami                              ace talent curators   \n",
       "199          miami                             1st merchant funding   \n",
       "200          miami                               miami dade college   \n",
       "201          miami                                           lennar   \n",
       "202          miami                                      dynamix int   \n",
       "203          miami                              university of miami   \n",
       "204          miami                                              adp   \n",
       "205          miami                              university of miami   \n",
       "206          miami                             amazon corporate llc   \n",
       "207          miami                               predictive science   \n",
       "208     washington                                             kpmg   \n",
       "209     washington                             amazon corporate llc   \n",
       "210     washington                                           zillow   \n",
       "211     washington                             amazon corporate llc   \n",
       "212     washington                                thirdeye data inc   \n",
       "213     washington                                           boeing   \n",
       "214     washington                                         t mobile   \n",
       "215     washington                                         winigent   \n",
       "216     washington                                        idealseat   \n",
       "217     washington                                           google   \n",
       "218     washington                                   lyft corporate   \n",
       "219     washington                                           textio   \n",
       "220     washington                                 general electric   \n",
       "221     washington                                     thrift books   \n",
       "222     washington                                      meter group   \n",
       "\n",
       "                                       location  \\\n",
       "0                           Manhattan Beach, CA   \n",
       "1                                  Torrance, CA   \n",
       "2                                    Downey, CA   \n",
       "3                                  Pasadena, CA   \n",
       "4                              Century City, CA   \n",
       "5                         Culver City, CA 90232   \n",
       "6                                 Hawthorne, CA   \n",
       "7                              Santa Monica, CA   \n",
       "8                               Los Angeles, CA   \n",
       "9                         Los Angeles, CA 90046   \n",
       "10                        Los Angeles, CA 90031   \n",
       "11                          Manhattan Beach, CA   \n",
       "12                              Los Angeles, CA   \n",
       "13                              Los Angeles, CA   \n",
       "14                      Downers Grove, IL 60515   \n",
       "15                            Chicago, IL 60606   \n",
       "16                                United States   \n",
       "17                                  Chicago, IL   \n",
       "18                                  Chicago, IL   \n",
       "19                                  Chicago, IL   \n",
       "20                                  Chicago, IL   \n",
       "21                                  Chicago, IL   \n",
       "22                                  Chicago, IL   \n",
       "23                                  Chicago, IL   \n",
       "24                                  Chicago, IL   \n",
       "25                                  Chicago, IL   \n",
       "26                                  Chicago, IL   \n",
       "27                            Chicago, IL 60606   \n",
       "28                              Lake Forest, IL   \n",
       "29                            San Francisco, CA   \n",
       "..                                          ...   \n",
       "193                               United States   \n",
       "194                             Miami, FL 33176   \n",
       "195                               United States   \n",
       "196                               United States   \n",
       "197  Miami, FL 33133 (North Coconut Grove area)   \n",
       "198                                   Miami, FL   \n",
       "199                             Miami, FL 33181   \n",
       "200             Miami, FL 33132 (Downtown area)   \n",
       "201                                   Miami, FL   \n",
       "202                   Fort Lauderdale, FL 33312   \n",
       "203                            Coral Gables, FL   \n",
       "204                                   Miami, FL   \n",
       "205                            Coral Gables, FL   \n",
       "206                               United States   \n",
       "207                               United States   \n",
       "208                           Seattle, WA 98104   \n",
       "209                                 Seattle, WA   \n",
       "210                           Seattle, WA 98101   \n",
       "211                                 Seattle, WA   \n",
       "212                                 Seattle, WA   \n",
       "213                                 Tukwila, WA   \n",
       "214          Bellevue, WA 98006 (Somerset area)   \n",
       "215                                Bellevue, WA   \n",
       "216                                 Seattle, WA   \n",
       "217                                Kirkland, WA   \n",
       "218                                 Seattle, WA   \n",
       "219                                 Seattle, WA   \n",
       "220                            Washington State   \n",
       "221                                 Tukwila, WA   \n",
       "222                                 Pullman, WA   \n",
       "\n",
       "                                               summary  \\\n",
       "0    our natural language processing and machine le...   \n",
       "1    experience with the hough transform support ve...   \n",
       "2    model document and present strategic solution ...   \n",
       "3    this individual will be responsible for applyi...   \n",
       "4    proven ability to do analytic or modeling work...   \n",
       "5    reporting to senior vp analytic business insig...   \n",
       "6    as a data scientist in this team you would ide...   \n",
       "7    we are looking for data scientist who are pass...   \n",
       "8    cr er des relations solides avec les quipes re...   \n",
       "9    the data scientist will work cross functionall...   \n",
       "10   lead predictive analytic and machine learning ...   \n",
       "11   e g real time data reporting and visualization...   \n",
       "12   proficiency in statistical analytic and machin...   \n",
       "13   co founded by accomplished scientist with deep...   \n",
       "14   proficiency in statistical data analysis and d...   \n",
       "15   serves as the resident data expert and share b...   \n",
       "16   this is a freelance data scientist position wh...   \n",
       "17   your primary focus will be in applying data mi...   \n",
       "18   demonstrated skills in data mining machine lea...   \n",
       "19   deep understanding of machine learning and dat...   \n",
       "20   individual will be mentored by a faculty membe...   \n",
       "21   interpret problems and develop solutions to bu...   \n",
       "22   this may include the creation of specialist in...   \n",
       "23   analyze financial data to extract relevant inf...   \n",
       "24   to apply please send your resume to careers pa...   \n",
       "25   the data scientist will work within the data a...   \n",
       "26   data scientist americas you will be ultimately...   \n",
       "27   analytic services where the data scientist wor...   \n",
       "28   the candidate will be responsible for working ...   \n",
       "29   komodo health is transforming predictive analy...   \n",
       "..                                                 ...   \n",
       "193  this is a freelance data scientist position wh...   \n",
       "194  the data scientist will create meaningful data...   \n",
       "195  advanced working knowledge of data mining usin...   \n",
       "196  as a machine learning software dev engineer on...   \n",
       "197  hands on with a high degree of expertise in da...   \n",
       "198  python or r for data science turn data into va...   \n",
       "199  we are looking for top data scientist experien...   \n",
       "200  researches and circulates grant program priori...   \n",
       "201  applied analytic team and inspire the adoption...   \n",
       "202  the candidate must have an extreme attention t...   \n",
       "203  uhealth university of miami health system sout...   \n",
       "204  at adp the worlds largest b2b cloud company ou...   \n",
       "205  experience with data warehousing and reporting...   \n",
       "206  working with scientist and other engineers to ...   \n",
       "207  this is a freelance data scientist position wh...   \n",
       "208  machine learning data visualization statistica...   \n",
       "209  4 years of relevant work experience in data sc...   \n",
       "210  experience mentoring leading other data scient...   \n",
       "211  2 years of industrial or research experience i...   \n",
       "212  build solutions that will be applied in real t...   \n",
       "213  as a member of the boeing commercial artificia...   \n",
       "214  conduct regular and ad hoc analyses data minin...   \n",
       "215  we are looking for people who see challenges a...   \n",
       "216  idealseat data scientist are focused on collec...   \n",
       "217  deep interest and aptitude in data metrics ana...   \n",
       "218  data scientist also build evaluation methodolo...   \n",
       "219  our augmented writing platform is delighting c...   \n",
       "220  work in technical teams in development deploym...   \n",
       "221  experience with pandas scikit learn and other ...   \n",
       "222  data engineering data mining data visualizatio...   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                    applied scientist   \n",
       "1                             image analysis scientist   \n",
       "2                     healthcare data scientist 127549   \n",
       "3                                     data scientist i   \n",
       "4                                       data scientist   \n",
       "5                                       data scientist   \n",
       "6                                       data scientist   \n",
       "7                                       data scientist   \n",
       "8                           digital data scientist h f   \n",
       "9                                       data scientist   \n",
       "10                                      data scientist   \n",
       "11   data scientist b2b ecommerce startup portfolio...   \n",
       "12                                      data scientist   \n",
       "13                  machine learning research engineer   \n",
       "14                       data scientist sales analytic   \n",
       "15                                      data scientist   \n",
       "16                                      data scientist   \n",
       "17                                      data scientist   \n",
       "18                                      data scientist   \n",
       "19                                      data scientist   \n",
       "20                                 statistical analyst   \n",
       "21                                      data scientist   \n",
       "22                                        data analyst   \n",
       "23                                quantitative analyst   \n",
       "24                              data scientist chicago   \n",
       "25                                      data scientist   \n",
       "26                                      data scientist   \n",
       "27                           data scientist consultant   \n",
       "28                          informatics data scientist   \n",
       "29                                      data scientist   \n",
       "..                                                 ...   \n",
       "193                                     data scientist   \n",
       "194                                     data scientist   \n",
       "195  data analyst devices customer engagement reloc...   \n",
       "196  machine learning software development engineer...   \n",
       "197                                     data scientist   \n",
       "198                                     data scientist   \n",
       "199                                     data scientist   \n",
       "200                   part time grant research analyst   \n",
       "201                                     data scientist   \n",
       "202                   market research and data analyst   \n",
       "203                                assistant scientist   \n",
       "204  principal product manager business intelligenc...   \n",
       "205                                   research analyst   \n",
       "206  artificial intelligence research software deve...   \n",
       "207                                     data scientist   \n",
       "208                                     data scientist   \n",
       "209               data scientist private label apparel   \n",
       "210                           principal data scientist   \n",
       "211                                     data scientist   \n",
       "212                                     data scientist   \n",
       "213                                     data scientist   \n",
       "214                           marketing data scientist   \n",
       "215                                     data scientist   \n",
       "216                                     data scientist   \n",
       "217                       product analyst data science   \n",
       "218                  data scientist all levels seattle   \n",
       "219                                     data scientist   \n",
       "220                                     data scientist   \n",
       "221     data scientist and predictive analytic manager   \n",
       "222                             applied data scientist   \n",
       "\n",
       "                                                  text predicted_salary_range  \n",
       "0    los angeles our natural language processing an...      $66000 to $150000  \n",
       "1    los angeles experience with the hough transfor...      $66000 to $150000  \n",
       "2    los angeles model document and present strateg...      $66000 to $150000  \n",
       "3    los angeles this individual will be responsibl...      $66000 to $150000  \n",
       "4    los angeles proven ability to do analytic or m...      $66000 to $150000  \n",
       "5    los angeles reporting to senior vp analytic bu...          above $150000  \n",
       "6    los angeles as a data scientist in this team y...          above $150000  \n",
       "7    los angeles we are looking for data scientist ...      $66000 to $150000  \n",
       "8    los angeles cr er des relations solides avec l...      $66000 to $150000  \n",
       "9    los angeles the data scientist will work cross...      $66000 to $150000  \n",
       "10   los angeles lead predictive analytic and machi...          above $150000  \n",
       "11   los angeles e g real time data reporting and v...      $66000 to $150000  \n",
       "12   los angeles proficiency in statistical analyti...      $66000 to $150000  \n",
       "13   los angeles co founded by accomplished scienti...      $66000 to $150000  \n",
       "14   chicago proficiency in statistical data analys...      $66000 to $150000  \n",
       "15   chicago serves as the resident data expert and...      $66000 to $150000  \n",
       "16   chicago this is a freelance data scientist pos...      $66000 to $150000  \n",
       "17   chicago your primary focus will be in applying...      $66000 to $150000  \n",
       "18   chicago demonstrated skills in data mining mac...      $66000 to $150000  \n",
       "19   chicago deep understanding of machine learning...      $66000 to $150000  \n",
       "20   chicago individual will be mentored by a facul...      $66000 to $150000  \n",
       "21   chicago interpret problems and develop solutio...      $66000 to $150000  \n",
       "22   chicago this may include the creation of speci...      $66000 to $150000  \n",
       "23   chicago analyze financial data to extract rele...           below $66000  \n",
       "24   chicago to apply please send your resume to ca...      $66000 to $150000  \n",
       "25   chicago the data scientist will work within th...      $66000 to $150000  \n",
       "26   chicago data scientist americas you will be ul...      $66000 to $150000  \n",
       "27   chicago analytic services where the data scien...      $66000 to $150000  \n",
       "28   chicago the candidate will be responsible for ...      $66000 to $150000  \n",
       "29   san francisco komodo health is transforming pr...      $66000 to $150000  \n",
       "..                                                 ...                    ...  \n",
       "193  houston this is a freelance data scientist pos...      $66000 to $150000  \n",
       "194  miami the data scientist will create meaningfu...          above $150000  \n",
       "195  miami advanced working knowledge of data minin...      $66000 to $150000  \n",
       "196  miami as a machine learning software dev engin...      $66000 to $150000  \n",
       "197  miami hands on with a high degree of expertise...      $66000 to $150000  \n",
       "198  miami python or r for data science turn data i...      $66000 to $150000  \n",
       "199  miami we are looking for top data scientist ex...          above $150000  \n",
       "200  miami researches and circulates grant program ...           below $66000  \n",
       "201  miami applied analytic team and inspire the ad...      $66000 to $150000  \n",
       "202  miami the candidate must have an extreme atten...           below $66000  \n",
       "203  miami uhealth university of miami health syste...      $66000 to $150000  \n",
       "204  miami at adp the worlds largest b2b cloud comp...      $66000 to $150000  \n",
       "205  miami experience with data warehousing and rep...           below $66000  \n",
       "206  miami working with scientist and other enginee...      $66000 to $150000  \n",
       "207  miami this is a freelance data scientist posit...      $66000 to $150000  \n",
       "208  washington machine learning data visualization...          above $150000  \n",
       "209  washington 4 years of relevant work experience...          above $150000  \n",
       "210  washington experience mentoring leading other ...          above $150000  \n",
       "211  washington 2 years of industrial or research e...          above $150000  \n",
       "212  washington build solutions that will be applie...          above $150000  \n",
       "213  washington as a member of the boeing commercia...      $66000 to $150000  \n",
       "214  washington conduct regular and ad hoc analyses...      $66000 to $150000  \n",
       "215  washington we are looking for people who see c...      $66000 to $150000  \n",
       "216  washington idealseat data scientist are focuse...      $66000 to $150000  \n",
       "217  washington deep interest and aptitude in data ...      $66000 to $150000  \n",
       "218  washington data scientist also build evaluatio...      $66000 to $150000  \n",
       "219  washington our augmented writing platform is d...          above $150000  \n",
       "220  washington work in technical teams in developm...      $66000 to $150000  \n",
       "221  washington experience with pandas scikit learn...          above $150000  \n",
       "222  washington data engineering data mining data v...      $66000 to $150000  \n",
       "\n",
       "[223 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_salary(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/predicted_salary_range.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
