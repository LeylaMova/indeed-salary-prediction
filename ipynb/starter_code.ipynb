{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "from lib.indeed_parsing import extract_posts, extract_posts_wo_salary\n",
    "from lib.preprocessing import clean_salary, clean_text, standardize, extract_keywords_into_dummies, is_keyword_in_title_or_summary, map_city, f\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities to collect job posts from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0"
   },
   "outputs": [],
   "source": [
    "cities = ['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', 'Los+Angeles', \n",
    "          'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', 'Portland', 'Phoenix', \n",
    "          'Denver', 'Houston', 'Miami', 'Washington']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and Collect - Location, Comapny, Salary, Title, Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = extract_posts(max_results_per_city=100, cities=cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "### Convert salary string and to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['salary'] = df['salary'].apply(clean_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleans texts from punctuations and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['company'] = df['company'].apply(clean_text)\n",
    "df['summary'] = df['summary'].apply(clean_text)\n",
    "df['title'] = df['title'].apply(clean_text)\n",
    "df['city'] = df['city'].astype(str)\n",
    "df['state'] = df['state'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize words like: sr -> senior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(standardize)\n",
    "df['summary'] = df['summary'].apply(standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't have to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries\n",
    "\n",
    "find salary percentile:\n",
    "- below twentieth 20th\n",
    "- between 20th and 85th \n",
    "- above 85th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x110e8b110>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAFkCAYAAAA37aFpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFcYAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110e9ced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.salary.plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twentieth = df['salary'].quantile(0.20)\n",
    "eightyfifth = df['salary'].quantile(0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentile_cls(row):\n",
    "    salary = row['salary']\n",
    "    \n",
    "    if salary < twentieth:\n",
    "        return 0\n",
    "    elif salary >= twentieth and salary < eightyfifth:\n",
    "        return 1  \n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['percentile_range'] = df.apply(percentile_cls, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "percentile_range       \n",
       "0                 count       111.000000\n",
       "                  mean      51260.058559\n",
       "                  std       10512.783993\n",
       "                  min       24000.000000\n",
       "                  25%       45925.000000\n",
       "                  50%       50000.000000\n",
       "                  75%       59992.250000\n",
       "                  max       69673.000000\n",
       "1                 count       358.000000\n",
       "                  mean     115979.497207\n",
       "                  std       26958.213723\n",
       "                  min       70000.000000\n",
       "                  25%       90981.000000\n",
       "                  50%      120000.000000\n",
       "                  75%      140000.000000\n",
       "                  max      160000.000000\n",
       "2                 count        83.000000\n",
       "                  mean     190481.927711\n",
       "                  std       24983.097430\n",
       "                  min      162500.000000\n",
       "                  25%      175000.000000\n",
       "                  50%      180000.000000\n",
       "                  75%      200000.000000\n",
       "                  max      300000.000000\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['percentile_range'])['salary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops.update(['experience','looking','using','work','working','join','company','strong','challenge',\n",
    "              '130k','net','1','10','17096','2','200k','250k','3','500','7444','74851','7644','7660'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = pd.DataFrame(df.groupby(['percentile_range'])['title'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsa = Pipeline([('vectorizer', TfidfVectorizer(stop_words=stops, ngram_range=(1,3))),\n",
    "                ('normalize', Normalizer(copy=False)),\n",
    "                ('svd', TruncatedSVD(n_components=100, n_iter=10, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = lsa.fit_transform(titles['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 99%\n"
     ]
    }
   ],
   "source": [
    "explained_variance = lsa.steps[2][1].explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(\n",
    "    int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " research\n",
      " analyst\n",
      " research analyst\n",
      " scientist\n",
      " specialist\n",
      " associate\n",
      " phd\n",
      " technician\n",
      " data\n",
      " research associate\n",
      "\n",
      "Cluster 1:\n",
      " data\n",
      " scientist\n",
      " data scientist\n",
      " senior\n",
      " engineer\n",
      " analyst\n",
      " learning\n",
      " machine learning\n",
      " machine\n",
      " senior data\n",
      "\n",
      "Cluster 2:\n",
      " data\n",
      " scientist\n",
      " data scientist\n",
      " senior\n",
      " senior data\n",
      " senior data scientist\n",
      " engineer\n",
      " quantitative\n",
      " analyst\n",
      " learning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "original_space_centroids = lsa.steps[2][1].inverse_transform(vec)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "\n",
    "terms = lsa.steps[0][1].get_feature_names()\n",
    "for i in range(3):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = df.groupby(['percentile_range'])['summary'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsa = Pipeline([('vectorizer', TfidfVectorizer(stop_words=stops, ngram_range=(1,3))),\n",
    "                ('normalize', Normalizer(copy=False)),\n",
    "                ('svd', TruncatedSVD(n_components=100, n_iter=10, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecs = lsa.fit_transform(summary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 100%\n"
     ]
    }
   ],
   "source": [
    "explained_variance = lsa.steps[2][1].explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(\n",
    "    int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " data\n",
      " research\n",
      " scientist\n",
      " analysis\n",
      " scientists\n",
      " quality\n",
      " interpret\n",
      " analyze\n",
      " analyst\n",
      " environmental\n",
      "\n",
      "Cluster 1:\n",
      " data\n",
      " learning\n",
      " machine\n",
      " machine learning\n",
      " scientist\n",
      " data scientist\n",
      " python\n",
      " analysis\n",
      " analytics\n",
      " modeling\n",
      "\n",
      "Cluster 2:\n",
      " data\n",
      " learning\n",
      " machine\n",
      " machine learning\n",
      " scientist\n",
      " data scientist\n",
      " team\n",
      " python\n",
      " data science\n",
      " science\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "original_space_centroids = lsa.steps[2][1].inverse_transform(vecs)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "\n",
    "terms = lsa.steps[0][1].get_feature_names()\n",
    "for i in range(3):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "three posibilities: baseline accuracy is 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['city'] = df.apply(map_city, axis=1)\n",
    "df['city_suburb'] = df['city'].apply(lambda x: 1 if 'Suburb' in x else 0)\n",
    "df = df.join(pd.get_dummies(df['city'].apply(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df['city'])\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.72222222222222221, 'test_score:', 0.67391304347826086)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['city','company','salary','state','summary','title','percentile_range'], axis=1)\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.71739130434782605, 'test_score:', 0.66666666666666663)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = extract_keywords_into_dummies(df, 'title','senior','associate','specialist','technician','lead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[['senior','associate','specialist','technician','lead']]\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.67874396135265702, 'test_score:', 0.6811594202898551)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['city','company','salary','state','summary','title','percentile_range'], axis=1)\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.72222222222222221, 'test_score:', 0.68840579710144922)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = extract_keywords_into_dummies(df, 'title','research','analyst','research analyst',\n",
    "                                   'data analyst','senior research','engineer','project',\n",
    "                                   'data scientist','machine learning','software',\n",
    "                                   'data engineer','quantitative','senior data scientist',\n",
    "                                   'director data','data science','statistical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['city','company','salary','state','summary','title','percentile_range'], axis=1)\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.7657004830917874, 'test_score:', 0.75362318840579712)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = extract_keywords_into_dummies(df, 'summary','management','data management',\n",
    "                                   'interpret','quality','python','modeling','intelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['city','company','salary','state','summary','title','percentile_range'], axis=1)\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.75362318840579712, 'test_score:', 0.75362318840579712)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['less_6yrs'] = df['summary'].apply(lambda x: 1 if 'two years' in x or '2 years' in x \n",
    "                                      or '3 years' in x or '5 years' in x or '6 years' in x \n",
    "                                      or 'five years' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['city','company','salary','state','summary','title','percentile_range'], axis=1)\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.75362318840579712, 'test_score:', 0.75362318840579712)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = extract_keywords_into_dummies(df, 'summary','phd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['city','company','salary','state','summary','title','percentile_range'], axis=1)\n",
    "y = df['percentile_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_score:', 0.7560386473429952, 'test_score:', 0.75362318840579712)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model = lr.fit(X_train, y_train)\n",
    "train_score = lr.score(X_train, y_train)\n",
    "test_score = lr.score(X_test, y_test)\n",
    "\n",
    "predict = lr.predict_proba(X_test)\n",
    "print('train_score:', train_score, 'test_score:', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(labels, model.coef_[0]), columns=['feature','coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>research</td>\n",
       "      <td>1.501062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>-1.333160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>1.300009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>-1.290937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington</td>\n",
       "      <td>-1.273834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>python</td>\n",
       "      <td>-1.266025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Houston</td>\n",
       "      <td>1.212878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New York</td>\n",
       "      <td>-1.166083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>technician</td>\n",
       "      <td>1.059504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>modeling</td>\n",
       "      <td>-1.007504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>specialist</td>\n",
       "      <td>0.991772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miami</td>\n",
       "      <td>0.977006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>0.970489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>-0.965815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>-0.932891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficient\n",
       "22          research     1.501062\n",
       "30  machine learning    -1.333160\n",
       "11           Phoenix     1.300009\n",
       "29    data scientist    -1.290937\n",
       "16        Washington    -1.273834\n",
       "42            python    -1.266025\n",
       "6            Houston     1.212878\n",
       "9           New York    -1.166083\n",
       "20        technician     1.059504\n",
       "43          modeling    -1.007504\n",
       "19        specialist     0.991772\n",
       "8              Miami     0.977006\n",
       "12        Pittsburgh     0.970489\n",
       "7        Los Angeles    -0.965815\n",
       "33      quantitative    -0.932891"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.reindex(results['coefficient'].abs().sort_values(ascending=False).index)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.50      0.60        28\n",
      "          1       0.76      0.92      0.83        91\n",
      "          2       0.75      0.32      0.44        19\n",
      "\n",
      "avg / total       0.75      0.75      0.73       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "8c22664b-92e4-4fc2-b7ac-fbac865845d3"
   },
   "source": [
    "#### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchCV = LogisticRegressionCV(\n",
    "    Cs=np.linspace(0.0001, 10, 100),\n",
    "    penalty='l1',\n",
    "    cv=10,\n",
    "    random_state=777,\n",
    "    solver='liblinear'\n",
    ")\n",
    "model = searchCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83749373053846754, 0.66996061428824583)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scores_[0].mean(), model.scores_[1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>-3.819671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>-3.744618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>technician</td>\n",
       "      <td>2.874048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lead</td>\n",
       "      <td>-2.792345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>modeling</td>\n",
       "      <td>-2.761259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>data science</td>\n",
       "      <td>-2.183251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>python</td>\n",
       "      <td>-1.883818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miami</td>\n",
       "      <td>1.817025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>1.809146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>senior</td>\n",
       "      <td>-1.769039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>research</td>\n",
       "      <td>1.740740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>quality</td>\n",
       "      <td>1.731439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>-1.686781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>1.676023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington</td>\n",
       "      <td>-1.598697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficient\n",
       "30  machine learning    -3.819671\n",
       "33      quantitative    -3.744618\n",
       "20        technician     2.874048\n",
       "21              lead    -2.792345\n",
       "43          modeling    -2.761259\n",
       "36      data science    -2.183251\n",
       "42            python    -1.883818\n",
       "8              Miami     1.817025\n",
       "12        Pittsburgh     1.809146\n",
       "17            senior    -1.769039\n",
       "22          research     1.740740\n",
       "41           quality     1.731439\n",
       "29    data scientist    -1.686781\n",
       "11           Phoenix     1.676023\n",
       "16        Washington    -1.598697"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(zip(labels, model.coef_[0]), columns=['feature','coefficient'])\n",
    "results.reindex(results['coefficient'].abs().sort_values(ascending=False).index)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = extract_posts_wo_salary(max_results_per_city=100, cities=cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle('data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['summary'] = test['summary'].apply(clean_text)\n",
    "test['title'] = test['title'].apply(clean_text)\n",
    "test['city'] = test['city'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['title'] = test['title'].apply(standardize)\n",
    "test['summary'] = test['summary'].apply(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['city'] = test.apply(map_city, axis=1)\n",
    "test['city_suburb'] = test['city'].apply(lambda x: 1 if 'Suburb' in x else 0)\n",
    "test = test.join(pd.get_dummies(test['city'].apply(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = extract_keywords_into_dummies(test, 'title','senior','associate','specialist','technician','lead')\n",
    "test = extract_keywords_into_dummies(test, 'title','research','analyst','research analyst','data analyst',\n",
    "                                     'senior research','engineer','project','data scientist','machine learning',\n",
    "                                     'software','data engineer','quantitative','senior data scientist',\n",
    "                                     'director data','data science','statistical')\n",
    "\n",
    "test = extract_keywords_into_dummies(test, 'summary','management','data management','interpret','quality',\n",
    "                                     'python','modeling','intelligence')\n",
    "\n",
    "test['less_6yrs'] = test['summary'].apply(lambda x: 1 if 'two years' in x or '2 years' in x \n",
    "                                          or '3 years' in x or '5 years' in x or '6 years' in x \n",
    "                                          or 'five years' in x else 0)\n",
    "\n",
    "test = extract_keywords_into_dummies(test, 'summary','phd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = test.drop(['city','company','summary','title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['percentile_range'] = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>city_suburb</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Chicago</th>\n",
       "      <th>Dallas</th>\n",
       "      <th>Denver</th>\n",
       "      <th>...</th>\n",
       "      <th>management</th>\n",
       "      <th>data management</th>\n",
       "      <th>interpret</th>\n",
       "      <th>quality</th>\n",
       "      <th>python</th>\n",
       "      <th>modeling</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>less_6yrs</th>\n",
       "      <th>phd</th>\n",
       "      <th>percentile_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>ProSearch Strategies, Inc.</td>\n",
       "      <td>a data scientist in the linguistics analytics ...</td>\n",
       "      <td>data analyst scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Cedars-Sinai</td>\n",
       "      <td>reporting to the research scientist and direct...</td>\n",
       "      <td>data analyst calnoc research</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Riot Games</td>\n",
       "      <td>collaborate with analysts and data scientists ...</td>\n",
       "      <td>technical data analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Neustar, Inc.</td>\n",
       "      <td>data strategy analyst communicating with clien...</td>\n",
       "      <td>data strategy analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>The Wonderful Company LLC</td>\n",
       "      <td>work with data scientists to create algorithms...</td>\n",
       "      <td>manager data science and analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>hunger to continue developing as a data scient...</td>\n",
       "      <td>senior data scientist content science algorithms</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>work with finance experts data scientists and ...</td>\n",
       "      <td>senior data analyst content analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>USC</td>\n",
       "      <td>supervises data entry programming staff perfor...</td>\n",
       "      <td>statistician ii</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>collaborate with our data scientists to map da...</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>HIRECLOUT</td>\n",
       "      <td>ingesting and working with huge data sets usin...</td>\n",
       "      <td>data engineer scala</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CrowdStrike</td>\n",
       "      <td>comfortable to work on very large data sets of...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>tronc</td>\n",
       "      <td>we are looking for a senior data scientist to ...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California Association of Realtors</td>\n",
       "      <td>focusing on data visualization data gathering ...</td>\n",
       "      <td>research and economics analyst data visualization</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Tillster</td>\n",
       "      <td>data scientist senior data scientist los angel...</td>\n",
       "      <td>data scientist senior data scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Praedicat, Inc.</td>\n",
       "      <td>who will report to the chief data scientist to...</td>\n",
       "      <td>quantitative developer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>MarketShare</td>\n",
       "      <td>well versed in using sql to process extract da...</td>\n",
       "      <td>marketing scientist attribution analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Praedicat, Inc.</td>\n",
       "      <td>who will report to the chief data scientist to...</td>\n",
       "      <td>quantitative developer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>MarketShare</td>\n",
       "      <td>well versed in using sql to process extract da...</td>\n",
       "      <td>marketing scientist attribution analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Cedars-Sinai</td>\n",
       "      <td>the cedars sinartificial intelligence regenera...</td>\n",
       "      <td>project scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>we have offices in cities around the world and...</td>\n",
       "      <td>research manager strategic insights analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Vivid Resourcing LLC</td>\n",
       "      <td>algorithms computer vision specialist los ange...</td>\n",
       "      <td>machine learning computer vision specialist lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>a data scientist on the marketing science team...</td>\n",
       "      <td>data science manager</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>UCLA Health</td>\n",
       "      <td>supervise research assistants on data entry an...</td>\n",
       "      <td>senior statistician</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles County Department of Human Resources</td>\n",
       "      <td>clinical laboratory scientist limited clinical...</td>\n",
       "      <td>medical technologist data systems</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>KORE1 Technologies</td>\n",
       "      <td>meet with researchers to explartificial intell...</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Connexity</td>\n",
       "      <td>minimum of years relevant analytic work experi...</td>\n",
       "      <td>senior data scientist analytic engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lawrence J. Ellison Institute for Transformati...</td>\n",
       "      <td>we are seeking a talented computational scient...</td>\n",
       "      <td>computational staff scientist statistician ii</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Kelton Global</td>\n",
       "      <td>kelton is a strategy consultancy that creates ...</td>\n",
       "      <td>senior analyst quantitative research</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>UCLA Health</td>\n",
       "      <td>knowledge and experience in data standardizati...</td>\n",
       "      <td>data scientist and application programmer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>experience with its data science libraries is ...</td>\n",
       "      <td>senior data engineer content analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>City National Bank</td>\n",
       "      <td>this position is responsible for supporting th...</td>\n",
       "      <td>compliance statistician</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>general technical problem solving skills with ...</td>\n",
       "      <td>research analyst marketing science</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>The Boston Consulting Group</td>\n",
       "      <td>scientific modelers together with data scienti...</td>\n",
       "      <td>scientific modeler</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>City National Bank</td>\n",
       "      <td>recalibrate all models annually to incorporate...</td>\n",
       "      <td>senior quantitative analyst ccar</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Riot Games</td>\n",
       "      <td>youll be part of the insights community at rio...</td>\n",
       "      <td>analytics manager north america</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Kantar Millward Brown</td>\n",
       "      <td>craft compelling stories working with your acc...</td>\n",
       "      <td>market research analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Elevano</td>\n",
       "      <td>our client is looking for a very strong senior...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Praedicat, Inc.</td>\n",
       "      <td>work with data scientists to build a data scie...</td>\n",
       "      <td>big data engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>BuzzFeed for Video Internship/Fellowship/Resid...</td>\n",
       "      <td>interest in social platforms and data we have ...</td>\n",
       "      <td>junior adaptations editor freelance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>UCLA Health</td>\n",
       "      <td>analyze data acquired martificial intelligence...</td>\n",
       "      <td>research associate ii</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>FullDeck</td>\n",
       "      <td>data scientist for our client a fast growing t...</td>\n",
       "      <td>junior data scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>UDig</td>\n",
       "      <td>leading conversations with client data owners ...</td>\n",
       "      <td>senior data strategy analysts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Council for Watershed Health</td>\n",
       "      <td>attend key stakeholder meetings and committee ...</td>\n",
       "      <td>senior scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Neustar, Inc.</td>\n",
       "      <td>manage data collection from clients data revie...</td>\n",
       "      <td>marketing data consultant</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>USC</td>\n",
       "      <td>the candidate will work in close collaboration...</td>\n",
       "      <td>phd scholar research associate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>HERO.jobs</td>\n",
       "      <td>they need a lead or principal level data scien...</td>\n",
       "      <td>lead data scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Kelton Global</td>\n",
       "      <td>kelton is a strategy consultancy that creates ...</td>\n",
       "      <td>analyst quantitative research</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>UCLA Health</td>\n",
       "      <td>analyze data acquired martificial intelligence...</td>\n",
       "      <td>research associate ii</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>ZestFinance</td>\n",
       "      <td>knowledge of data structures and parallelizati...</td>\n",
       "      <td>senior assoc machine learning modeler data sci...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Riot Games</td>\n",
       "      <td>as a researcher you ll join the insights disci...</td>\n",
       "      <td>researcher</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Lieberman Research Worldwide (LRW)</td>\n",
       "      <td>you ll work on building a cloud based integrat...</td>\n",
       "      <td>software engineer data analytics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            city                                            company  \\\n",
       "754  Los Angeles                         ProSearch Strategies, Inc.   \n",
       "755  Los Angeles                                       Cedars-Sinai   \n",
       "756  Los Angeles                                         Riot Games   \n",
       "757  Los Angeles                                      Neustar, Inc.   \n",
       "758  Los Angeles                          The Wonderful Company LLC   \n",
       "759  Los Angeles                                            Netflix   \n",
       "761  Los Angeles                                            Netflix   \n",
       "764  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "765  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "768  Los Angeles                                                USC   \n",
       "769  Los Angeles                                             Luxoft   \n",
       "772  Los Angeles                                          HIRECLOUT   \n",
       "777  Los Angeles                                        CrowdStrike   \n",
       "783  Los Angeles                                              tronc   \n",
       "788  Los Angeles                 California Association of Realtors   \n",
       "790  Los Angeles                                           Tillster   \n",
       "791  Los Angeles                                    Praedicat, Inc.   \n",
       "792  Los Angeles                                        MarketShare   \n",
       "793  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "798  Los Angeles                                    Praedicat, Inc.   \n",
       "799  Los Angeles                                        MarketShare   \n",
       "800  Los Angeles                                       Cedars-Sinai   \n",
       "802  Los Angeles                                           BuzzFeed   \n",
       "805  Los Angeles                               Vivid Resourcing LLC   \n",
       "806  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "808  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "816  Los Angeles                                        UCLA Health   \n",
       "818  Los Angeles   Los Angeles County Department of Human Resources   \n",
       "819  Los Angeles                                 KORE1 Technologies   \n",
       "821  Los Angeles                                          Connexity   \n",
       "..           ...                                                ...   \n",
       "834  Los Angeles  Lawrence J. Ellison Institute for Transformati...   \n",
       "836  Los Angeles                                      Kelton Global   \n",
       "838  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "844  Los Angeles                                        UCLA Health   \n",
       "845  Los Angeles                                            Netflix   \n",
       "847  Los Angeles                                 City National Bank   \n",
       "848  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "849  Los Angeles                        The Boston Consulting Group   \n",
       "853  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "858  Los Angeles                                 City National Bank   \n",
       "859  Los Angeles                                         Riot Games   \n",
       "861  Los Angeles                              Kantar Millward Brown   \n",
       "862  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "863  Los Angeles                                            Elevano   \n",
       "865  Los Angeles                                    Praedicat, Inc.   \n",
       "867  Los Angeles  BuzzFeed for Video Internship/Fellowship/Resid...   \n",
       "868  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "873  Los Angeles                                        UCLA Health   \n",
       "875  Los Angeles                                           FullDeck   \n",
       "876  Los Angeles                                               UDig   \n",
       "878  Los Angeles                       Council for Watershed Health   \n",
       "879  Los Angeles                                      Neustar, Inc.   \n",
       "882  Los Angeles                                                USC   \n",
       "883  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "889  Los Angeles                                          HERO.jobs   \n",
       "890  Los Angeles                                      Kelton Global   \n",
       "891  Los Angeles                                        UCLA Health   \n",
       "894  Los Angeles                                        ZestFinance   \n",
       "896  Los Angeles                                         Riot Games   \n",
       "898  Los Angeles                 Lieberman Research Worldwide (LRW)   \n",
       "\n",
       "                                               summary  \\\n",
       "754  a data scientist in the linguistics analytics ...   \n",
       "755  reporting to the research scientist and direct...   \n",
       "756  collaborate with analysts and data scientists ...   \n",
       "757  data strategy analyst communicating with clien...   \n",
       "758  work with data scientists to create algorithms...   \n",
       "759  hunger to continue developing as a data scient...   \n",
       "761  work with finance experts data scientists and ...   \n",
       "764  you ll work on building a cloud based integrat...   \n",
       "765  you ll work on building a cloud based integrat...   \n",
       "768  supervises data entry programming staff perfor...   \n",
       "769  collaborate with our data scientists to map da...   \n",
       "772  ingesting and working with huge data sets usin...   \n",
       "777  comfortable to work on very large data sets of...   \n",
       "783  we are looking for a senior data scientist to ...   \n",
       "788  focusing on data visualization data gathering ...   \n",
       "790  data scientist senior data scientist los angel...   \n",
       "791  who will report to the chief data scientist to...   \n",
       "792  well versed in using sql to process extract da...   \n",
       "793  you ll work on building a cloud based integrat...   \n",
       "798  who will report to the chief data scientist to...   \n",
       "799  well versed in using sql to process extract da...   \n",
       "800  the cedars sinartificial intelligence regenera...   \n",
       "802  we have offices in cities around the world and...   \n",
       "805  algorithms computer vision specialist los ange...   \n",
       "806  a data scientist on the marketing science team...   \n",
       "808  you ll work on building a cloud based integrat...   \n",
       "816  supervise research assistants on data entry an...   \n",
       "818  clinical laboratory scientist limited clinical...   \n",
       "819  meet with researchers to explartificial intell...   \n",
       "821  minimum of years relevant analytic work experi...   \n",
       "..                                                 ...   \n",
       "834  we are seeking a talented computational scient...   \n",
       "836  kelton is a strategy consultancy that creates ...   \n",
       "838  you ll work on building a cloud based integrat...   \n",
       "844  knowledge and experience in data standardizati...   \n",
       "845  experience with its data science libraries is ...   \n",
       "847  this position is responsible for supporting th...   \n",
       "848  general technical problem solving skills with ...   \n",
       "849  scientific modelers together with data scienti...   \n",
       "853  you ll work on building a cloud based integrat...   \n",
       "858  recalibrate all models annually to incorporate...   \n",
       "859  youll be part of the insights community at rio...   \n",
       "861  craft compelling stories working with your acc...   \n",
       "862  you ll work on building a cloud based integrat...   \n",
       "863  our client is looking for a very strong senior...   \n",
       "865  work with data scientists to build a data scie...   \n",
       "867  interest in social platforms and data we have ...   \n",
       "868  you ll work on building a cloud based integrat...   \n",
       "873  analyze data acquired martificial intelligence...   \n",
       "875  data scientist for our client a fast growing t...   \n",
       "876  leading conversations with client data owners ...   \n",
       "878  attend key stakeholder meetings and committee ...   \n",
       "879  manage data collection from clients data revie...   \n",
       "882  the candidate will work in close collaboration...   \n",
       "883  you ll work on building a cloud based integrat...   \n",
       "889  they need a lead or principal level data scien...   \n",
       "890  kelton is a strategy consultancy that creates ...   \n",
       "891  analyze data acquired martificial intelligence...   \n",
       "894  knowledge of data structures and parallelizati...   \n",
       "896  as a researcher you ll join the insights disci...   \n",
       "898  you ll work on building a cloud based integrat...   \n",
       "\n",
       "                                                 title  city_suburb  Atlanta  \\\n",
       "754                             data analyst scientist            0      0.0   \n",
       "755                       data analyst calnoc research            0      0.0   \n",
       "756                             technical data analyst            0      0.0   \n",
       "757                              data strategy analyst            0      0.0   \n",
       "758                 manager data science and analytics            0      0.0   \n",
       "759   senior data scientist content science algorithms            0      0.0   \n",
       "761              senior data analyst content analytics            0      0.0   \n",
       "764                   software engineer data analytics            0      0.0   \n",
       "765                   software engineer data analytics            0      0.0   \n",
       "768                                    statistician ii            0      0.0   \n",
       "769                                      data engineer            0      0.0   \n",
       "772                                data engineer scala            0      0.0   \n",
       "777                              senior data scientist            0      0.0   \n",
       "783                              senior data scientist            0      0.0   \n",
       "788  research and economics analyst data visualization            0      0.0   \n",
       "790               data scientist senior data scientist            0      0.0   \n",
       "791                             quantitative developer            0      0.0   \n",
       "792          marketing scientist attribution analytics            0      0.0   \n",
       "793                   software engineer data analytics            0      0.0   \n",
       "798                             quantitative developer            0      0.0   \n",
       "799          marketing scientist attribution analytics            0      0.0   \n",
       "800                                  project scientist            0      0.0   \n",
       "802      research manager strategic insights analytics            0      0.0   \n",
       "805  machine learning computer vision specialist lo...            0      0.0   \n",
       "806                               data science manager            0      0.0   \n",
       "808                   software engineer data analytics            0      0.0   \n",
       "816                                senior statistician            0      0.0   \n",
       "818                  medical technologist data systems            0      0.0   \n",
       "819                                       data analyst            0      0.0   \n",
       "821            senior data scientist analytic engineer            0      0.0   \n",
       "..                                                 ...          ...      ...   \n",
       "834      computational staff scientist statistician ii            0      0.0   \n",
       "836               senior analyst quantitative research            0      0.0   \n",
       "838                   software engineer data analytics            0      0.0   \n",
       "844          data scientist and application programmer            0      0.0   \n",
       "845             senior data engineer content analytics            0      0.0   \n",
       "847                            compliance statistician            0      0.0   \n",
       "848                 research analyst marketing science            0      0.0   \n",
       "849                                 scientific modeler            0      0.0   \n",
       "853                   software engineer data analytics            0      0.0   \n",
       "858                   senior quantitative analyst ccar            0      0.0   \n",
       "859                    analytics manager north america            0      0.0   \n",
       "861                            market research analyst            0      0.0   \n",
       "862                   software engineer data analytics            0      0.0   \n",
       "863                              senior data scientist            0      0.0   \n",
       "865                                  big data engineer            0      0.0   \n",
       "867                junior adaptations editor freelance            0      0.0   \n",
       "868                   software engineer data analytics            0      0.0   \n",
       "873                              research associate ii            0      0.0   \n",
       "875                              junior data scientist            0      0.0   \n",
       "876                      senior data strategy analysts            0      0.0   \n",
       "878                                   senior scientist            0      0.0   \n",
       "879                          marketing data consultant            0      0.0   \n",
       "882                     phd scholar research associate            0      0.0   \n",
       "883                   software engineer data analytics            0      0.0   \n",
       "889                                lead data scientist            0      0.0   \n",
       "890                      analyst quantitative research            0      0.0   \n",
       "891                              research associate ii            0      0.0   \n",
       "894  senior assoc machine learning modeler data sci...            0      0.0   \n",
       "896                                         researcher            0      0.0   \n",
       "898                   software engineer data analytics            0      0.0   \n",
       "\n",
       "     Austin  Chicago  Dallas  Denver        ...         management  \\\n",
       "754     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "755     0.0      0.0     0.0     0.0        ...                1.0   \n",
       "756     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "757     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "758     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "759     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "761     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "764     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "765     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "768     0.0      0.0     0.0     0.0        ...                1.0   \n",
       "769     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "772     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "777     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "783     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "788     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "790     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "791     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "792     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "793     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "798     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "799     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "800     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "802     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "805     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "806     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "808     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "816     0.0      0.0     0.0     0.0        ...                1.0   \n",
       "818     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "819     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "821     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "..      ...      ...     ...     ...        ...                ...   \n",
       "834     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "836     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "838     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "844     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "845     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "847     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "848     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "849     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "853     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "858     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "859     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "861     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "862     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "863     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "865     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "867     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "868     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "873     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "875     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "876     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "878     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "879     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "882     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "883     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "889     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "890     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "891     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "894     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "896     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "898     0.0      0.0     0.0     0.0        ...                0.0   \n",
       "\n",
       "     data management  interpret  quality  python  modeling  intelligence  \\\n",
       "754              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "755              1.0        0.0      0.0     0.0       0.0           0.0   \n",
       "756              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "757              0.0        0.0      0.0     0.0       1.0           0.0   \n",
       "758              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "759              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "761              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "764              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "765              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "768              1.0        0.0      0.0     0.0       0.0           0.0   \n",
       "769              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "772              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "777              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "783              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "788              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "790              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "791              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "792              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "793              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "798              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "799              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "800              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "802              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "805              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "806              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "808              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "816              1.0        0.0      1.0     0.0       0.0           0.0   \n",
       "818              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "819              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "821              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "..               ...        ...      ...     ...       ...           ...   \n",
       "834              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "836              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "838              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "844              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "845              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "847              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "848              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "849              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "853              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "858              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "859              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "861              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "862              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "863              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "865              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "867              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "868              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "873              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "875              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "876              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "878              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "879              0.0        0.0      1.0     0.0       0.0           0.0   \n",
       "882              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "883              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "889              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "890              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "891              0.0        0.0      0.0     0.0       0.0           1.0   \n",
       "894              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "896              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "898              0.0        0.0      0.0     0.0       0.0           0.0   \n",
       "\n",
       "     less_6yrs  phd  percentile_range  \n",
       "754          0  0.0                 1  \n",
       "755          0  0.0                 0  \n",
       "756          0  0.0                 1  \n",
       "757          0  0.0                 1  \n",
       "758          0  0.0                 2  \n",
       "759          0  0.0                 1  \n",
       "761          0  0.0                 1  \n",
       "764          0  0.0                 1  \n",
       "765          0  0.0                 1  \n",
       "768          0  0.0                 1  \n",
       "769          0  0.0                 1  \n",
       "772          0  0.0                 1  \n",
       "777          0  0.0                 1  \n",
       "783          0  0.0                 1  \n",
       "788          0  0.0                 0  \n",
       "790          0  0.0                 1  \n",
       "791          0  0.0                 2  \n",
       "792          0  0.0                 1  \n",
       "793          0  0.0                 1  \n",
       "798          0  0.0                 2  \n",
       "799          0  0.0                 1  \n",
       "800          0  0.0                 1  \n",
       "802          0  0.0                 0  \n",
       "805          0  0.0                 1  \n",
       "806          0  0.0                 2  \n",
       "808          0  0.0                 1  \n",
       "816          0  0.0                 1  \n",
       "818          0  0.0                 1  \n",
       "819          0  0.0                 1  \n",
       "821          0  0.0                 1  \n",
       "..         ...  ...               ...  \n",
       "834          0  0.0                 1  \n",
       "836          0  0.0                 2  \n",
       "838          0  0.0                 1  \n",
       "844          0  0.0                 1  \n",
       "845          0  0.0                 1  \n",
       "847          0  0.0                 1  \n",
       "848          0  0.0                 0  \n",
       "849          0  0.0                 1  \n",
       "853          0  0.0                 1  \n",
       "858          1  0.0                 1  \n",
       "859          0  0.0                 1  \n",
       "861          0  0.0                 0  \n",
       "862          0  0.0                 1  \n",
       "863          0  0.0                 1  \n",
       "865          0  0.0                 1  \n",
       "867          0  0.0                 1  \n",
       "868          0  0.0                 1  \n",
       "873          0  0.0                 0  \n",
       "875          0  0.0                 1  \n",
       "876          0  0.0                 1  \n",
       "878          0  0.0                 1  \n",
       "879          0  0.0                 1  \n",
       "882          0  0.0                 0  \n",
       "883          0  0.0                 1  \n",
       "889          0  0.0                 1  \n",
       "890          0  0.0                 1  \n",
       "891          0  0.0                 0  \n",
       "894          0  0.0                 1  \n",
       "896          0  0.0                 0  \n",
       "898          0  0.0                 1  \n",
       "\n",
       "[64 rows x 52 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['city'] == 'Los Angeles']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
